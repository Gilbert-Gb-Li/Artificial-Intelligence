# 编码-解码结构
- 代码[encoder_decoder]
- 由编码器与解码器构成
- 作用
    - 可以完成图像去噪任务
    - 也可以完成图像的超分辨率采样任务
    - 完成图像的分割任务

# 对抗生成网络
### 1. 手写数字生成模型
- 代码[gen_img]
- 输入数据为
    - X：标签（OneHot标签）       
    - y：手写数字图像
- 网络模型：反卷积
- 损失函数：均方误差(MSE)
- **模型存在的问题**      
    输入是固定的，则输出也是固定的，但生成网络需要一定的随机性，输出不同风格的数字。

    若希望训练好的生成网络可以有多种多样的输出，那么如何控制呢?         
    **模型一旦训练好，里面的参数便是固定的，因此输入相同，则输出也必然相同**。

### 2. 带有随机性手写数字生成模型
#### 随机性方法
若希望通过多次相同的输入标签得到的输出为不同风格的手写数字图像，需要在输入标签基础上并上一定的噪声，形成一个多对多的生成网络，实现输出的随机性。

#### 存在的问题  
使用MSE作为loss意味着每个元素均需对应上
约束较强，对于低频特征约束。

### 3. 对抗生成网络
- 代码[gans, DCGAN]；以下以手写数字为例，代码为DCGAN
- 由生成器与判别器组成，引入判别网络来替换掉原有的均方误差或交叉熵，判别生成的数字是否是所需的结果，对抗生成网络对于高频特征约束较强
- 生成器 DCGAN$generator
    - 输入：噪声数据及标签
        - z：噪声，[N, h, w, c]
        - y：one_hot后的标签
    - 输出：图片数据
    - 模型：反卷积
        1. 噪声z[n1, m]与y[n2, m]连接
        1. 全连接
        2. z[N, h, w, c]与y[n, h, w, c]连接
        3. 多个反卷积: tf.layers.conv2d_transpose
            - 反卷积： 上采样【多出来的部分补零】 + 普通卷积
            - stride，步长，若为2，表示在原有的基础上扩大2倍再进行卷积
        4. z[N, h, w, c]与y[n, h, w, c]连接
        5. 普通卷积将通道变成1个
- 判别器 DCGAN$discriminator
    - 输入：图片数据+标签
    - 输出：0,1
    - 模型：全连接
- loss
    - 可以只用生成器，loss为均方误差，但向量太长计算代价过高
    - 使用对抗生成网络，每层反卷积学得一部分特征，使得生成数据特征的分布尽可能的与真是数据接近
- 训练 model$train
    - 生成器比较难训练，而判别器相对来说容易
    - 实际训练时可加大生成器的训练比例，使生成器与判别器的loss相近
